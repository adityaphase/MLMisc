{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic predict NN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al2r2oPVZufm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7oVBNEWZ3TL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/livinundershadows/TitanicNN/master/titanic/train.csv\"\n",
        "titanic = pd.read_csv(url)\n",
        "#select relevant columns\n",
        "df1 = titanic[['Age', 'Fare', 'SibSp', 'Parch']]\n",
        "df2 = titanic[['Survived']] #y -> people who survived\n",
        "df1 = df1.to_numpy()\n",
        "df2 = df2.to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbNNJHrqgP-Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82b1cfa7-dd77-4a5e-e92c-bf5b46894736"
      },
      "source": [
        "x = df1\n",
        "y = df2\n",
        "x = np.nan_to_num(x, nan=0)\n",
        "x = torch.from_numpy(x).type(torch.FloatTensor)\n",
        "y = torch.from_numpy(y).type(torch.LongTensor)\n",
        "print(x.shape, y.shape)"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([891, 4]) torch.Size([891, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad4piWzanTfq",
        "colab_type": "code",
        "outputId": "50552f6e-5a1d-47de-a392-e83499559f53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "class BinaryClassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(BinaryClassifier, self).__init__()\n",
        "    self.fc1 = nn.Linear(4,3)\n",
        "    self.fc2 = nn.Linear(3,4)\n",
        "  #This must be implemented\n",
        "  def forward(self,x):\n",
        "        #Output of the first layer\n",
        "        x = self.fc1(x)\n",
        "        #activation\n",
        "        x = torch.tanh(x)\n",
        "        #This produces output\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "        \n",
        "    #This function takes an input and predicts the class, (0 or 1)        \n",
        "  def predict(self,x):\n",
        "        #Apply softmax to output. \n",
        "        pred = F.softmax(self.forward(x))\n",
        "        ans = []\n",
        "        #Pick the class with maximum weight\n",
        "        for t in pred:\n",
        "            if t[0]>t[1]:\n",
        "                ans.append(0)\n",
        "            else:\n",
        "                ans.append(1)\n",
        "        return torch.tensor(ans)\n",
        "model = BinaryClassifier()\n",
        "print(model)"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BinaryClassifier(\n",
            "  (fc1): Linear(in_features=4, out_features=3, bias=True)\n",
            "  (fc2): Linear(in_features=3, out_features=4, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pto7AVb3rh47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criteria = nn.CrossEntropyLoss()\n",
        "optimiser = optim.Adam(model.parameters(), lr=0.01)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKVwhr25r-J9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "fb97dcf8-fd5d-41b6-953e-6217e00713db"
      },
      "source": [
        "# lets train the nn\n",
        "epochs = 1000\n",
        "loss = 0\n",
        "for i in range(epochs):\n",
        "  yPred = model.forward(x)\n",
        "  y = y.squeeze_()\n",
        "  loss = criteria(yPred,y)\n",
        "  if (i % 100 == 0):\n",
        "    print(\"Loss: {}\".format(loss.item()))\n",
        "  optimiser.zero_grad()\n",
        "  loss.backward()\n",
        "  optimiser.step()"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 1.647923469543457\n",
            "Loss: 0.6704092621803284\n",
            "Loss: 0.6094908118247986\n",
            "Loss: 0.6012620329856873\n",
            "Loss: 0.5974895358085632\n",
            "Loss: 0.5953292846679688\n",
            "Loss: 0.5938417911529541\n",
            "Loss: 0.5923894643783569\n",
            "Loss: 0.5891389846801758\n",
            "Loss: 0.5815443396568298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho6ovxQOsjY0",
        "colab_type": "code",
        "outputId": "d2d4bf09-c9b7-4f61-fa70-3b0a7e630f0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(model.predict(x),y))"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7171717171717171\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oL9nCTafAGC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dfb1d8b7-98ae-49c5-ed41-8bec7f542a19"
      },
      "source": [
        "# test on data\n",
        "url1 = \"https://raw.githubusercontent.com/livinundershadows/TitanicNN/master/titanic/test.csv\"\n",
        "titanic = pd.read_csv(url1)\n",
        "#select relevant columns\n",
        "df11 = titanic[['Age', 'Fare', 'SibSp', 'Parch']]\n",
        "df11 = df11.to_numpy()\n",
        "\n",
        "x1 = df11\n",
        "x1 = torch.from_numpy(x1).type(torch.FloatTensor)\n",
        "print(x1.shape)"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([418, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht5cny5tf9Qd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d4dbb28a-d925-48f1-eaec-27f93ad0c196"
      },
      "source": [
        "yp1 = model.predict(x1)\n",
        "yp1 = yp1.numpy()"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}